{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "import string\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 119811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>i really do not understand your point xa it se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a xc xa majority of canadians can and has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>listen if you dont wanna get married to a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>c xe c b u ea n xu u ed ng u u b u eddng bi u ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                                  you fuck your dad\n",
       "1       0  20120528192215Z  i really do not understand your point xa it se...\n",
       "2       0              NaN  a xc xa majority of canadians can and has been...\n",
       "3       0              NaN  listen if you dont wanna get married to a man ...\n",
       "4       0  20120619094753Z  c xe c b u ea n xu u ed ng u u b u eddng bi u ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/prepr_full_train.csv'\n",
    "train_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(train_data_))\n",
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2647\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the drudge report n n n nyou wo not see this s...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120618222256Z</td>\n",
       "      <td>ian xa roger clemens is the fucking man and ne...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618213617Z</td>\n",
       "      <td>agree with alan you are an extremest idiot you...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>really &lt;SIGNS&gt; n ni see marc lamont hill on va...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620003825Z</td>\n",
       "      <td>really suck is not the word when many of our n...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment  \\\n",
       "0       0              NaN  the drudge report n n n nyou wo not see this s...   \n",
       "1       0  20120618222256Z  ian xa roger clemens is the fucking man and ne...   \n",
       "2       1  20120618213617Z  agree with alan you are an extremest idiot you...   \n",
       "3       0              NaN  really <SIGNS> n ni see marc lamont hill on va...   \n",
       "4       0  20120620003825Z  really suck is not the word when many of our n...   \n",
       "\n",
       "         Usage  \n",
       "0   PublicTest  \n",
       "1   PublicTest  \n",
       "2   PublicTest  \n",
       "3  PrivateTest  \n",
       "4  PrivateTest  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/prepr_valid.csv'\n",
    "valid_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(valid_data_))\n",
    "valid_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>like this if you are a tribe fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>you idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>i am a woman babs and the only war on women i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>wow you benefitted so many wins this year from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>haha green me red you now loser whos winning n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       0  20120603163526Z                   like this if you are a tribe fan\n",
       "1       1  20120531215447Z                                          you idiot\n",
       "2       1  20120823164228Z  i am a woman babs and the only war on women i ...\n",
       "3       1  20120826010752Z  wow you benefitted so many wins this year from...\n",
       "4       1  20120602223825Z  haha green me red you now loser whos winning n..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/prepr_test.csv'\n",
    "test_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(test_data_))\n",
    "test_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data_.dropna(axis=0, how='any')\n",
    "valid_data = valid_data_\n",
    "test_data = test_data_\n",
    "\n",
    "valid_size = len(valid_data)\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "X_train = train_data['Comment']\n",
    "y_train = train_data['Insult']\n",
    "X_valid = valid_data['Comment']\n",
    "y_valid = valid_data['Insult']\n",
    "X_test = test_data['Comment']\n",
    "y_test = test_data['Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data in words: 45475008\n",
      "Most common words (+UNK) [['UNK', 0], ['<EOS>', 0], ['<PAD>', 0], ['<SIGNS>', 56993], ('the', 364016)]\n",
      "Sample data [7, 73, 24, 3284, 6, 130, 23, 13, 243, 24]\n",
      "Dict: 0\n",
      "Reverse dict: UNK\n",
      "Counter: ['UNK', 0]\n",
      "Data: 7\n",
      "Words: you fuck y\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 200000\n",
    "\n",
    "def build_vocabulary(words):\n",
    "    counter_words = collections.Counter(words)\n",
    "    count = [['UNK', -3], ['<EOS>', 0], ['<PAD>', 0], ['<SIGNS>', counter_words['<SIGNS>']]]\n",
    "    count.extend(counter_words.most_common(vocabulary_size - 4))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0\n",
    "            unk_count = unk_count + 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "words = ' '.join(X_train)\n",
    "print ('Length of train data in words:', len(words))\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_vocabulary(words.split(' '))\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10])\n",
    "\n",
    "print ('Dict:', dictionary['UNK'])\n",
    "print ('Reverse dict:', reverse_dictionary[0])\n",
    "print ('Counter:', count[dictionary['UNK']])\n",
    "print ('Data:', data[0])\n",
    "print ('Words:', words[:10])\n",
    "del words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2id(word):\n",
    "    if word in dictionary:\n",
    "        return dictionary[word]\n",
    "    else:\n",
    "        return 0 # UNK\n",
    "\n",
    "def id2word(id_):\n",
    "    return reverse_dictionary[id_]\n",
    "\n",
    "\n",
    "def comment2vec(comment):\n",
    "    global comment_size\n",
    "    split = comment.split(' ')\n",
    "    res = np.array([word2id(word) for word in split], dtype='int')\n",
    "    return res\n",
    "\n",
    "def vec2comment(vec):\n",
    "    global comment_size\n",
    "    return ' '.join([id2word(id_) for id_ in vec])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledBatchGenerator(object):\n",
    "    def __init__(self, comments, batch_size, comment_size, labels):\n",
    "        self._comments = comments\n",
    "        self._num_comments = len(comments)\n",
    "        self._batch_size = batch_size\n",
    "        self._comment_size = comment_size\n",
    "        self._labels = labels\n",
    "        segment = self._num_comments // batch_size\n",
    "        self._cursor = [offset * segment for offset in range(batch_size)]\n",
    "        \n",
    "    def _next_batch(self, step):\n",
    "        batch = np.zeros(shape=(self._batch_size,1), dtype=np.int)\n",
    "        for b in range(self._batch_size):\n",
    "            comment = comment2vec(self._comments[self._cursor[b]])\n",
    "            N = len(comment)\n",
    "            if step < N:\n",
    "                batch[b,0] = comment[step]\n",
    "            elif step == N:\n",
    "                batch[b,0] = word2id('<EOS>')\n",
    "            elif step > N:\n",
    "                batch[b,0] = word2id('<PAD>')\n",
    "            if step == self._comment_size - 1:\n",
    "                if N > self._comment_size - 1:\n",
    "                    batch[b,0] = word2id('<EOS>')\n",
    "                self._cursor[b] = (self._cursor[b] + 1) % self._num_comments\n",
    "        return batch\n",
    "    \n",
    "    def next(self):\n",
    "        batches = []\n",
    "        batches_labels = [self._labels[self._cursor[b]] for b in range(self._batch_size)]\n",
    "        for step in range(0, self._comment_size):\n",
    "            batches.append(self._next_batch(step))\n",
    "        return batches, batches_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comment_size = 100\n",
    "batch_size = 64\n",
    "\n",
    "train_batches, train_labels = LabeledBatchGenerator(X_train.as_matrix(), train_size, comment_size, y_train.as_matrix()).next()\n",
    "valid_batches, valid_labels = LabeledBatchGenerator(X_valid.as_matrix(), valid_size, comment_size, y_valid.as_matrix()).next()\n",
    "test_batches, test_labels = LabeledBatchGenerator(X_test.as_matrix(), test_size, comment_size, y_test.as_matrix()).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(train_batches).reshape(comment_size, train_size).T\n",
    "y_train = np.asarray(train_labels).reshape(-1)\n",
    "X_valid = np.asarray(valid_batches).reshape(comment_size, valid_size).T\n",
    "y_valid = np.asarray(valid_labels).reshape(-1)\n",
    "X_test = np.asarray(test_batches).reshape(comment_size, test_size).T\n",
    "y_test = np.asarray(test_labels).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119063, 100)\n",
      "(2647, 100)\n",
      "(2235, 100)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, concatenate, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.core import Dropout, Reshape\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "patch_size = [3,4,5]\n",
    "num_filters = 32\n",
    "\n",
    "inputs = Input(shape=(comment_size,))\n",
    "embed_inputs = Embedding(vocabulary_size, embedding_size, trainable=True)(inputs)\n",
    "\n",
    "output_0 = Conv1D(num_filters, kernel_size=patch_size[0], activation='relu', \n",
    "                      kernel_regularizer=l2(0.001), padding='same')(embed_inputs)\n",
    "output_0 = MaxPooling1D(pool_size=2, strides=1, padding='same')(output_0)\n",
    "\n",
    "output_1 = Conv1D(num_filters, kernel_size=patch_size[1], activation='relu', \n",
    "                      kernel_regularizer=l2(0.001), padding='same')(embed_inputs)\n",
    "output_1 = MaxPooling1D(pool_size=2, strides=1, padding='same')(output_1)\n",
    "\n",
    "output_2 = Conv1D(num_filters, kernel_size=patch_size[2], activation='relu', \n",
    "                      kernel_regularizer=l2(0.001), padding='same')(embed_inputs)\n",
    "output_2 = MaxPooling1D(pool_size=2, strides=1, padding='same')(output_2)\n",
    "\n",
    "output = concatenate([output_0, output_1, output_2], axis=1)\n",
    "print('Concatenated:', output.shape)\n",
    "\n",
    "output = Reshape(((comment_size * len(patch_size) ) * num_filters,))(output)\n",
    "print ('Reshaped:', output.shape)\n",
    "\n",
    "output = Dropout(rate=0.5)(output)\n",
    "output = Dense(100, activation=None, kernel_regularizer=l2(0.001))(output) \n",
    "\n",
    "output = Dropout(rate=0.5)(output)\n",
    "output = Dense(1, activation=None, kernel_regularizer=l2(0.001))(output)\n",
    "\n",
    "act_output = Activation('sigmoid')(output)\n",
    "print ('Final:',act_output.shape)\n",
    "model = Model(inputs=inputs, outputs=act_output)\n",
    "\n",
    "optimizer = Adam(lr=0.01, decay=0.1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())\n",
    "print (model.output_shape)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train.reshape(-1,1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=(X_valid, y_valid.reshape(-1,1)),\n",
    "          verbose=1)\n",
    "score, acc = model.evaluate(X_valid, y_valid.reshape(-1,1),\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "model.save_weights(filepath='./checkpoint_dir/wordCNNkeras_wiki')\n",
    "\n",
    "print('Valid score:', score)\n",
    "print('Valid accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC-ROC: 0.761189333079\n",
      "Valid AUC-ROC: 0.736563249102\n",
      "Test AUC-ROC: 0.657590890066\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.round(model.predict(X_train))\n",
    "print ('Train AUC-ROC:',roc_auc_score(y_train, y_train_pred.reshape(-1)))\n",
    "\n",
    "y_valid_pred = np.round(model.predict(X_valid))\n",
    "print ('Valid AUC-ROC:',roc_auc_score(y_valid, y_valid_pred.reshape(-1)))\n",
    "\n",
    "y_test_pred = np.round(model.predict(X_test))\n",
    "\n",
    "print ('Test AUC-ROC:',roc_auc_score(y_test, y_test_pred.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
