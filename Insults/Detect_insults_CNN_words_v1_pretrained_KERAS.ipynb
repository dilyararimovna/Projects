{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, io\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "import string\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 3947\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>i really do not understand your point xa it se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a xc xa majority of canadians can and has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>listen if you dont wanna get married to a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>c xe c b u ea n xu u ed ng u u b u eddng bi u ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                                  you fuck your dad\n",
       "1       0  20120528192215Z  i really do not understand your point xa it se...\n",
       "2       0              NaN  a xc xa majority of canadians can and has been...\n",
       "3       0              NaN  listen if you dont wanna get married to a man ...\n",
       "4       0  20120619094753Z  c xe c b u ea n xu u ed ng u u b u eddng bi u ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/prepr_train.csv'\n",
    "train_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(train_data_))\n",
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2647\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the drudge report n n n nyou wo not see this s...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120618222256Z</td>\n",
       "      <td>ian xa roger clemens is the fucking man and ne...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618213617Z</td>\n",
       "      <td>agree with alan you are an extremest idiot you...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>really &lt;SIGNS&gt; n ni see marc lamont hill on va...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620003825Z</td>\n",
       "      <td>really suck is not the word when many of our n...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment  \\\n",
       "0       0              NaN  the drudge report n n n nyou wo not see this s...   \n",
       "1       0  20120618222256Z  ian xa roger clemens is the fucking man and ne...   \n",
       "2       1  20120618213617Z  agree with alan you are an extremest idiot you...   \n",
       "3       0              NaN  really <SIGNS> n ni see marc lamont hill on va...   \n",
       "4       0  20120620003825Z  really suck is not the word when many of our n...   \n",
       "\n",
       "         Usage  \n",
       "0   PublicTest  \n",
       "1   PublicTest  \n",
       "2   PublicTest  \n",
       "3  PrivateTest  \n",
       "4  PrivateTest  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/prepr_valid.csv'\n",
    "valid_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(valid_data_))\n",
    "valid_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>like this if you are a tribe fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>you idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>i am a woman babs and the only war on women i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>wow you benefitted so many wins this year from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>haha green me red you now loser whos winning n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       0  20120603163526Z                   like this if you are a tribe fan\n",
       "1       1  20120531215447Z                                          you idiot\n",
       "2       1  20120823164228Z  i am a woman babs and the only war on women i ...\n",
       "3       1  20120826010752Z  wow you benefitted so many wins this year from...\n",
       "4       1  20120602223825Z  haha green me red you now loser whos winning n..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/prepr_test.csv'\n",
    "test_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(test_data_))\n",
    "test_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data_\n",
    "valid_data = valid_data_\n",
    "test_data = test_data_\n",
    "\n",
    "valid_size = len(valid_data)\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "X_train = train_data['Comment']\n",
    "y_train = train_data['Insult']\n",
    "X_valid = valid_data['Comment']\n",
    "y_valid = valid_data['Insult']\n",
    "X_test = test_data['Comment']\n",
    "y_test = test_data['Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n",
      "Vocabulary size: 400000\n",
      "Embedding size:  50\n"
     ]
    }
   ],
   "source": [
    "filename = '../glove.6B/glove.6B.50d.txt'\n",
    "\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = io.open(filename,'r' , encoding='utf-8')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "\n",
    "\n",
    "vocabulary, embedding_ = loadGloVe(filename)\n",
    "vocabulary_size = len(vocabulary)\n",
    "embedding_size = len(embedding_[0])\n",
    "embedding = np.asarray(embedding_)\n",
    "\n",
    "print ('Vocabulary size:', vocabulary_size)\n",
    "print ('Embedding size: ', embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledBatchGenerator(object):\n",
    "    def __init__(self, comments, batch_size, comment_size, labels):\n",
    "        self._comments = comments\n",
    "        self._num_comments = len(comments)\n",
    "        self._batch_size = batch_size\n",
    "        self._comment_size = comment_size\n",
    "        self._labels = labels\n",
    "        segment = self._num_comments // batch_size\n",
    "        self._cursor = [offset * segment for offset in range(batch_size)]\n",
    "        \n",
    "    def _next_batch(self, step):\n",
    "        batch = np.zeros(shape=(self._batch_size,1), dtype=np.int)\n",
    "        for b in range(self._batch_size):\n",
    "            batch[b,0] = self._comments[self._cursor[b]][step]\n",
    "            if step == self._comment_size - 1:\n",
    "                self._cursor[b] = (self._cursor[b] + 1) % self._num_comments\n",
    "        return batch\n",
    "    \n",
    "    def next(self):\n",
    "        batches = []\n",
    "        batches_labels = [self._labels[self._cursor[b]] for b in range(self._batch_size)]\n",
    "        for step in range(0, self._comment_size):\n",
    "            batches.append(self._next_batch(step))\n",
    "        return batches, batches_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comment_size = 100\n",
    "batch_size = 64\n",
    "\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(comment_size)\n",
    "pretrain = vocab_processor.fit(vocabulary)\n",
    "\n",
    "X_train_ = np.array(list(vocab_processor.transform(X_train.as_matrix())))\n",
    "X_valid_ = np.array(list(vocab_processor.transform(X_valid.as_matrix())))\n",
    "X_test_ = np.array(list(vocab_processor.transform(X_test.as_matrix())))\n",
    "\n",
    "train_batches, train_labels = LabeledBatchGenerator(X_train_, train_size, comment_size, y_train.as_matrix()).next()\n",
    "valid_batches, valid_labels = LabeledBatchGenerator(X_valid_, valid_size, comment_size, y_valid.as_matrix()).next()\n",
    "test_batches, test_labels = LabeledBatchGenerator(X_test_, test_size, comment_size, y_test.as_matrix()).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(train_batches).reshape(comment_size, train_size).T\n",
    "y_train = np.asarray(train_labels).reshape(-1)\n",
    "X_valid = np.asarray(valid_batches).reshape(comment_size, valid_size).T\n",
    "y_valid = np.asarray(valid_labels).reshape(-1)\n",
    "X_test = np.asarray(test_batches).reshape(comment_size, test_size).T\n",
    "y_test = np.asarray(test_labels).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3947, 100)\n",
      "(2647, 100)\n",
      "(2235, 100)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_valid.shape)\n",
    "print (X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, concatenate, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.core import Dropout, Reshape\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated: (?, 300, 128)\n",
      "Reshaped: (?, 38400)\n",
      "Final: (?, 1)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_20 (InputLayer)            (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)         (None, 100, 50)       20000000                                     \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)               (None, 100, 128)      19328                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)               (None, 100, 128)      25728                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)               (None, 100, 128)      32128                                        \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D)  (None, 100, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D)  (None, 100, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D)  (None, 100, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)     (None, 300, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)             (None, 38400)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)             (None, 38400)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_37 (Dense)                 (None, 100)           3840100                                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_38 (Dense)                 (None, 1)             101                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 1)             0                                            \n",
      "====================================================================================================\n",
      "Total params: 23,917,385.0\n",
      "Trainable params: 3,917,385.0\n",
      "Non-trainable params: 20,000,000.0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "(None, 1)\n",
      "Train...\n",
      "Train on 3947 samples, validate on 2647 samples\n",
      "Epoch 1/10\n",
      "3904/3947 [============================>.] - ETA: 0s - loss: 11.6882 - acc: 0.7287"
     ]
    }
   ],
   "source": [
    "patch_size = [3,4,5]\n",
    "num_filters = 128\n",
    "regul_coef = 0.0001\n",
    "inputs = Input(shape=(comment_size,))\n",
    "embed_inputs = Embedding(vocabulary_size, embedding_size, weights=[embedding], trainable=False)(inputs)\n",
    "\n",
    "output_0 = Conv1D(num_filters, kernel_size=patch_size[0], activation='relu', \n",
    "                      kernel_regularizer=l2(regul_coef), padding='same')(embed_inputs)\n",
    "output_0 = MaxPooling1D(pool_size=2, strides=1, padding='same')(output_0)\n",
    "\n",
    "output_1 = Conv1D(num_filters, kernel_size=patch_size[1], activation='relu', \n",
    "                      kernel_regularizer=l2(regul_coef), padding='same')(embed_inputs)\n",
    "output_1 = MaxPooling1D(pool_size=2, strides=1, padding='same')(output_1)\n",
    "\n",
    "output_2 = Conv1D(num_filters, kernel_size=patch_size[2], activation='relu', \n",
    "                      kernel_regularizer=l2(regul_coef), padding='same')(embed_inputs)\n",
    "output_2 = MaxPooling1D(pool_size=2, strides=1, padding='same')(output_2)\n",
    "\n",
    "output = concatenate([output_0, output_1, output_2], axis=1)\n",
    "print('Concatenated:', output.shape)\n",
    "\n",
    "output = Reshape(((comment_size * len(patch_size) ) * num_filters,))(output)\n",
    "print ('Reshaped:', output.shape)\n",
    "\n",
    "output = Dropout(rate=0.5)(output)\n",
    "output = Dense(100, activation=None, kernel_regularizer=l2(regul_coef))(output) \n",
    "\n",
    "output = Dropout(rate=0.5)(output)\n",
    "output = Dense(1, activation=None, kernel_regularizer=l2(regul_coef))(output)\n",
    "\n",
    "act_output = Activation('sigmoid')(output)\n",
    "print ('Final:',act_output.shape)\n",
    "model = Model(inputs=inputs, outputs=act_output)\n",
    "\n",
    "optimizer = Adam(lr=0.1, decay=0.1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())\n",
    "print (model.output_shape)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train.reshape(-1,1),\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=(X_valid, y_valid.reshape(-1,1)),\n",
    "          verbose=1)\n",
    "score, acc = model.evaluate(X_valid, y_valid.reshape(-1,1),\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "model.save_weights(filepath='./checkpoint_dir/wordCNNkeras_glove')\n",
    "\n",
    "print('Valid score:', score)\n",
    "print('Valid accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC-ROC: 0.5\n",
      "Valid AUC-ROC: 0.5\n",
      "Test AUC-ROC: 0.5\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.round(model.predict(X_train))\n",
    "print ('Train AUC-ROC:',roc_auc_score(y_train, y_train_pred.reshape(-1)))\n",
    "\n",
    "y_valid_pred = np.round(model.predict(X_valid))\n",
    "print ('Valid AUC-ROC:',roc_auc_score(y_valid, y_valid_pred.reshape(-1)))\n",
    "\n",
    "y_test_pred = np.round(model.predict(X_test))\n",
    "\n",
    "print ('Test AUC-ROC:',roc_auc_score(y_test, y_test_pred.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
