{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Detecting insults "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task\n",
    "\n",
    "**Goal:** Insults and rough language detecting.\n",
    "\n",
    "**Data:** Kaggle dataset of 3947 comments\n",
    "\n",
    "<img src=\"dataset.png\">\n",
    "\n",
    "**Metrics:** AUC-ROC\n",
    "\n",
    "**Required:** 85\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Existing results\n",
    "\n",
    "<img src=\"leaderboard.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Existing approaches\n",
    "\n",
    "* TF-IDF for n-grams\n",
    "* Hadcrafted data preprocessing\n",
    "* Feature selection using SelectKBest and chi2 (sklearn)\n",
    "* LogisticRegression, SVÐ¡, RandomForest, GradientBoosting (sklearn)\n",
    "* Ensemble classifiers\n",
    "* Stanford Natural Language Processing (not in the best results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data preprocessing\n",
    "* convert letters to lowercase OR left capital letters (signs of high tone)\n",
    "* replace apostrophes $'m \\rightarrow am$, $n't \\rightarrow not$\n",
    "* delete multiple letters ($mooom \\rightarrow mom$ but still $moom \\rightarrow moom$ because $cool \\rightarrow cool$) \n",
    "* delete or group together sequencies of one-letter words: $m.o.m. \\rightarrow mom$, $m~~o~~m \\rightarrow mom$\n",
    "* delete links, htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data preprocessing\n",
    "\n",
    "* replace punctuation marks in sequence $!!??!!\\rightarrow <SIGNS>$\n",
    "* replace positive smiles with $<POSIT>$, negative smiles with $<NEGAT>$\n",
    "* complement $f...ck, f..., f..ck, f.ck$ using vocabulary\n",
    "* very long comments: take first N tokens, take last N tokens\n",
    "* delete or replace nicknames (@stupid_boy) with $you$\n",
    "* replace all other punctuation marks with spaces\n",
    "* delete multiple spaces, new lines, tabs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CNN for word embeddings \n",
    "\n",
    "**+** standard baseline for text classification\n",
    "\n",
    "**+** simple for implementation, very fast\n",
    "\n",
    "**-** extraordinary insults can be not in the vocabulary\n",
    "\n",
    "**-** location invariance and local compositionality lose info about word order\n",
    "\n",
    "<img src='cnn_cls.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNN (LSTM and GRU)\n",
    "\n",
    "by Sasha Sax (\"Flame Wars: Automatic Insult Detection\", Stanford)\n",
    "\n",
    "* All character-level RNNs outperformed the baseline models in terms of F1 while underperforming the AUC values.\n",
    "* Tree-LSTM to better catch character and part-of-word sense (rather than whole words), negations, to better use info throught the comment.\n",
    "<img align=\"center\" src='sasha_results.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CNN and RNN \n",
    "by Theodora Chu (Comment Abuse Classification with Deep Learning)\n",
    "\n",
    "150.000 comments from Wikipedia Detox\n",
    "\n",
    "<img align=\"center\" src='theodora_acc.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Considered approaches\n",
    "\n",
    "* **CNN** for word embeddings - 1 week\n",
    "* **CNN** character level (works well on large datasets but underperforms for small datasets) - 1 week\n",
    "* **RNN** character LSTM and GRU - 1 weeks\n",
    "* **RNN** word LSTM and GRU - 1 week\n",
    "* **Ensembles** of charcter-level and word-level - 2 week\n",
    "* **Russian**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
