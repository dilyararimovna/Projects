{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "import string\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 3947\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/train.csv'\n",
    "train_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(train_data_))\n",
    "train_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2647\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"THE DRUDGE REPORT\\\\n\\\\n\\\\n\\\\nYou won't see th...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120618222256Z</td>\n",
       "      <td>\"@ian21\\xa0\"Roger Clemens is the fucking man, ...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618213617Z</td>\n",
       "      <td>\"Agree with Alan you are an extremest idiot.  ...</td>\n",
       "      <td>PublicTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Really?\\\\n\\\\nI see Marc Lamont Hill on variou...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620003825Z</td>\n",
       "      <td>\"Really suck isn't the word, when many of our ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment  \\\n",
       "0       0              NaN  \"THE DRUDGE REPORT\\\\n\\\\n\\\\n\\\\nYou won't see th...   \n",
       "1       0  20120618222256Z  \"@ian21\\xa0\"Roger Clemens is the fucking man, ...   \n",
       "2       1  20120618213617Z  \"Agree with Alan you are an extremest idiot.  ...   \n",
       "3       0              NaN  \"Really?\\\\n\\\\nI see Marc Lamont Hill on variou...   \n",
       "4       0  20120620003825Z  \"Really suck isn't the word, when many of our ...   \n",
       "\n",
       "         Usage  \n",
       "0   PublicTest  \n",
       "1   PublicTest  \n",
       "2   PublicTest  \n",
       "3  PrivateTest  \n",
       "4  PrivateTest  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/test_with_solutions.csv'\n",
    "valid_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(valid_data_))\n",
    "valid_data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 2235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>\"like this if you are a tribe fan\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>\"you're idiot.......................\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>\"I am a woman Babs, and the only \"war on women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>\"WOW &amp; YOU BENEFITTED SO MANY WINS THIS YEAR F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>\"haha green me red you now loser whos winning ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             Date                                            Comment\n",
       "0   1  20120603163526Z                 \"like this if you are a tribe fan\"\n",
       "1   2  20120531215447Z              \"you're idiot.......................\"\n",
       "2   3  20120823164228Z  \"I am a woman Babs, and the only \"war on women...\n",
       "3   4  20120826010752Z  \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...\n",
       "4   5  20120602223825Z  \"haha green me red you now loser whos winning ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './data/test.csv'\n",
    "test_data_ = pd.read_csv(filename)\n",
    "print ('Data size:', len(test_data_))\n",
    "test_data_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(data):\n",
    "    max_sym_len = 0\n",
    "    max_word_len = 0\n",
    "    lens_in_words = []\n",
    "\n",
    "    for i, comment in enumerate(data['Comment']):\n",
    "        data.iloc[i,2] = data.iloc[i,2].lower()\n",
    "        data.iloc[i,2] = re.sub('n\\'t', ' not', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\'m', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\'s', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\'re', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\'ve', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\'d', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub(' im ', ' i', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub(' ur ', ' you ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\? ', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('[!?]+', ' mysignssymbol ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub(r'href=[\\'\"]?([^\\'\" >]+)', ' ', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('[^a-z]+', ' ', data.iloc[i,2]) # replace everything not lowercase literals with space\n",
    "        data.iloc[i,2] = re.sub('\\s+', ' ',  data.iloc[i,2] ).strip() #replace multiple spaces\n",
    "        for letter in string.ascii_lowercase: #replace multiple letters (3 and more) \n",
    "            data.iloc[i,2] = re.sub(letter * 3 + '+', letter,  data.iloc[i,2] ).strip() \n",
    "        data.iloc[i,2] = re.sub('mysignssymbol', '<SIGNS>', data.iloc[i,2])\n",
    "        data.iloc[i,2] = re.sub('\\s+', ' ',  data.iloc[i,2] ).strip() #replace multiple spaces\n",
    "        if max_sym_len < len(comment):\n",
    "            max_sym_len = len(comment)\n",
    "        if max_word_len < len(comment.split(' ')):\n",
    "            max_word_len = len(comment.split(' '))\n",
    "        lens_in_words.append(len(comment.split(' ')))\n",
    "        \n",
    "    print ('Max comment length in symbols:', max_sym_len)\n",
    "    print ('Max comment length in words:  ', max_word_len)\n",
    "    plt.plot(np.arange(len(lens_in_words)), np.asarray(lens_in_words))\n",
    "    plt.xlabel('Comment')\n",
    "    plt.ylabel('Length in words')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max comment length in symbols: 17805\n",
      "Max comment length in words:   2407\n",
      "Max comment length in symbols: 20030\n",
      "Max comment length in words:   1419\n",
      "Max comment length in symbols: 1437\n",
      "Max comment length in words:   224\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27dedf33e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = data_preprocessing(train_data_)\n",
    "valid_data = data_preprocessing(valid_data_)\n",
    "test_data = data_preprocessing(test_data_)\n",
    "\n",
    "valid_size = len(valid_data)\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "X_train = train_data['Comment']\n",
    "y_train = train_data['Insult']\n",
    "X_valid = valid_data['Comment']\n",
    "y_valid = valid_data['Insult']\n",
    "X_test = test_data['Comment']\n",
    "y_test = test_data['id']\n",
    "\n",
    "test_data_ = test_data_.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data in words: 728927\n",
      "Most common words (+UNK) [['UNK', 0], ['<EOS>', 0], ['<PAD>', 0], ['<SIGNS>', 1747], ('the', 4780)]\n",
      "Sample data [5, 74, 19, 705, 10, 98, 23, 13, 254, 19]\n",
      "Dict: 0\n",
      "Reverse dict: UNK\n",
      "Counter: ['UNK', 0]\n",
      "Data: 5\n",
      "Words: you fuck y\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 50000\n",
    "\n",
    "def build_vocabulary(words):\n",
    "    counter_words = collections.Counter(words)\n",
    "    count = [['UNK', -3], ['<EOS>', 0], ['<PAD>', 0], ['<SIGNS>', counter_words['<SIGNS>']]]\n",
    "    count.extend(counter_words.most_common(vocabulary_size - 4))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0\n",
    "            unk_count = unk_count + 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "words = ' '.join(X_train)\n",
    "print ('Length of train data in words:', len(words))\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_vocabulary(words.split(' '))\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10])\n",
    "\n",
    "print ('Dict:', dictionary['UNK'])\n",
    "print ('Reverse dict:', reverse_dictionary[0])\n",
    "print ('Counter:', count[dictionary['UNK']])\n",
    "print ('Data:', data[0])\n",
    "print ('Words:', words[:10])\n",
    "del words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2id(word):\n",
    "    if word in dictionary:\n",
    "        return dictionary[word]\n",
    "    else:\n",
    "        return 0 # UNK\n",
    "\n",
    "def id2word(id_):\n",
    "    return reverse_dictionary[id_]\n",
    "\n",
    "\n",
    "def comment2vec(comment):\n",
    "    global comment_size\n",
    "    split = comment.split(' ')\n",
    "    res = np.array([word2id(word) for word in split], dtype='int')\n",
    "    return res\n",
    "\n",
    "def vec2comment(vec):\n",
    "    global comment_size\n",
    "    return ' '.join([id2word(id_) for id_ in vec])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LabeledBatchGenerator(object):\n",
    "    def __init__(self, comments, batch_size, comment_size, labels):\n",
    "        self._comments = comments\n",
    "        self._num_comments = len(comments)\n",
    "        self._batch_size = batch_size\n",
    "        self._comment_size = comment_size\n",
    "        self._labels = labels\n",
    "        segment = self._num_comments // batch_size\n",
    "        self._cursor = [offset * segment for offset in range(batch_size)]\n",
    "        \n",
    "    def _next_batch(self, step):\n",
    "        batch = np.zeros(shape=(self._batch_size,1), dtype=np.int)\n",
    "        for b in range(self._batch_size):\n",
    "            comment = comment2vec(self._comments[self._cursor[b]])\n",
    "            N = len(comment)\n",
    "            if step < N:\n",
    "                batch[b,0] = comment[step]\n",
    "            elif step == N:\n",
    "                batch[b,0] = word2id('<EOS>')\n",
    "            elif step > N:\n",
    "                batch[b,0] = word2id('<PAD>')\n",
    "            if step == self._comment_size - 1:\n",
    "                if N > self._comment_size - 1:\n",
    "                    batch[b,0] = word2id('<EOS>')\n",
    "                self._cursor[b] = (self._cursor[b] + 1) % self._num_comments\n",
    "        return batch\n",
    "    \n",
    "    def next(self):\n",
    "        batches = []\n",
    "        batches_labels = [self._labels[self._cursor[b]] for b in range(self._batch_size)]\n",
    "        for step in range(0, self._comment_size):\n",
    "            batches.append(self._next_batch(step))\n",
    "        return batches, batches_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comment_size = 100\n",
    "batch_size = 64\n",
    "valid_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "train_batch_generator = LabeledBatchGenerator(X_train.as_matrix(), batch_size, comment_size, y_train.as_matrix())\n",
    "valid_batch_generator = LabeledBatchGenerator(X_valid.as_matrix(), valid_batch_size, comment_size, y_valid.as_matrix())\n",
    "test_batch_generator = LabeledBatchGenerator(X_test.as_matrix(), test_batch_size, comment_size, y_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(losses_, mean_losses_, train_aucs_, valid_aucs_, frequency):\n",
    "    plt.plot(losses_)\n",
    "    plt.title('Losses')\n",
    "    plt.xlabel('Step')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(frequency * np.arange(1,len(mean_losses_)+1), mean_losses_)\n",
    "    plt.title('MeanLosses')\n",
    "    plt.xlabel('Step')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_aucs_, label='Train AUC-ROC')\n",
    "    plt.plot(frequency * np.arange(1,len(valid_aucs_)+1), valid_aucs_, label='Valid AUC-ROC')\n",
    "    plt.xlabel('Step')\n",
    "    plt.title('AUC-ROC')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 93)\n",
      "Graph is ready!\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 128\n",
    "patch_size = [3,4,5]\n",
    "num_filters = 32\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    tf_keep_prob = tf.placeholder(tf.float32)\n",
    "    tf_data = list()\n",
    "    tf_labels = tf.placeholder(tf.float32, shape=[None,1])\n",
    "    for _ in range(comment_size):\n",
    "        tf_data.append(tf.placeholder(tf.int32, shape=[None, 1]))  \n",
    "    tf_inputs = tf.concat(tf_data[:comment_size], axis=1)    \n",
    "    tf_embedded_inputs = tf.nn.embedding_lookup(tf_embeddings, tf_inputs) # batch_size, comment_size, embed_size\n",
    "\n",
    "    tf_w0 = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size[0], embedding_size, num_filters], stddev=0.1))\n",
    "    tf_w1 = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size[1], embedding_size, num_filters], stddev=0.1))\n",
    "    tf_w2 = tf.Variable(tf.truncated_normal(\n",
    "            [patch_size[2], embedding_size, num_filters], stddev=0.1))\n",
    "    \n",
    "    def multi_layer_cnn(data):\n",
    "        output = []\n",
    "        conv = tf.nn.conv1d(data, tf_w0, 1, padding='SAME')\n",
    "        conv = tf.nn.relu(conv)\n",
    "        pool = tf.nn.max_pool(tf.expand_dims(conv,-1), [1, 1, 2, 1], [1, 1, 1, 1], 'VALID')\n",
    "        pool = tf.nn.relu(pool)\n",
    "        pool = tf.squeeze(pool, axis=3)\n",
    "        output.append(pool)\n",
    "        \n",
    "        conv = tf.nn.conv1d(data, tf_w1, 1, padding='SAME')\n",
    "        conv = tf.nn.relu(conv)\n",
    "        pool = tf.nn.max_pool(tf.expand_dims(conv,-1), [1, 1, 2, 1], [1, 1, 1, 1], 'VALID')\n",
    "        pool = tf.nn.relu(pool)\n",
    "        pool = tf.squeeze(pool, axis=3)\n",
    "        output.append(pool)\n",
    "        \n",
    "        conv = tf.nn.conv1d(data, tf_w2, 1, padding='SAME')\n",
    "        conv = tf.nn.relu(conv)\n",
    "        pool = tf.nn.max_pool(tf.expand_dims(conv,-1), [1, 1, 2, 1], [1, 1, 1, 1], 'VALID')\n",
    "        pool = tf.nn.relu(pool)\n",
    "        pool = tf.squeeze(pool, axis=3)\n",
    "        output.append(pool)\n",
    "        \n",
    "        output = tf.concat(output, axis=2)\n",
    "        print (output.shape)\n",
    "        \n",
    "        shape = output.get_shape().as_list()\n",
    "        reshape = tf.reshape(output, [-1, shape[1] * shape[2]])\n",
    "        return tf.layers.dense(inputs=reshape, units=1, activation=None)\n",
    "\n",
    "    #tf_logits = tf.nn.dropout(multi_layer_cnn(tf_embedded_inputs), tf_keep_prob)\n",
    "    tf_logits = multi_layer_cnn(tf_embedded_inputs)\n",
    "    tf_loss = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf_logits, labels=tf_labels)) )\n",
    "    tf_global_step = tf.Variable(0, trainable=False)\n",
    "    tf_learning_rate = tf.train.exponential_decay(0.01, tf_global_step,\n",
    "                                               1000, 0.9, staircase=True)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    #train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    tf_optimizer = tf.train.AdamOptimizer(tf_learning_rate)\n",
    "    tf_grads = tf_optimizer.compute_gradients(tf_loss)\n",
    "    tf_op = tf_optimizer.apply_gradients(tf_grads, global_step=tf_global_step)\n",
    "\n",
    "    tf_prediction = tf.round(tf.sigmoid(tf_logits))\n",
    "    tf_auc_roc, tf_update_oper = tf.metrics.auc(tf_labels, tf_prediction)\n",
    "    \n",
    "    print('Graph is ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "\n",
      "Step 100\n",
      "True: [0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0]\n",
      "Pred: [0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0]\n",
      "Train loss: 0.98392\n",
      "Train batch AUC-ROC: 0.69134 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.69618\n",
      "\n",
      "Step 200\n",
      "True: [0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1]\n",
      "Pred: [0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1]\n",
      "Train loss: 0.05791\n",
      "Train batch AUC-ROC: 0.80993 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.79234\n",
      "\n",
      "Step 300\n",
      "True: [1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
      "Pred: [1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0]\n",
      "Train loss: 0.00584\n",
      "Train batch AUC-ROC: 0.84642 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.83460\n",
      "\n",
      "Step 400\n",
      "True: [0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0]\n",
      "Pred: [0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0]\n",
      "Train loss: 0.00226\n",
      "Train batch AUC-ROC: 0.86584 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.85428\n",
      "\n",
      "Step 500\n",
      "True: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "Pred: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      "Train loss: 0.00140\n",
      "Train batch AUC-ROC: 0.87579 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.86631\n",
      "\n",
      "Step 600\n",
      "True: [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "Pred: [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
      " 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "Train loss: 0.00093\n",
      "Train batch AUC-ROC: 0.88287 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.87476\n",
      "\n",
      "Step 700\n",
      "True: [0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0]\n",
      "Pred: [0 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0]\n",
      "Train loss: 0.00079\n",
      "Train batch AUC-ROC: 0.88786 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.88051\n",
      "\n",
      "Step 800\n",
      "True: [0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "Pred: [0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "Train loss: 0.00045\n",
      "Train batch AUC-ROC: 0.89130 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.88496\n",
      "\n",
      "Step 900\n",
      "True: [1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "Pred: [1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1]\n",
      "Train loss: 0.00064\n",
      "Train batch AUC-ROC: 0.89423 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.88858\n",
      "\n",
      "Step 1000\n",
      "True: [0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0]\n",
      "Pred: [0 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0]\n",
      "Train loss: 0.00062\n",
      "Train batch AUC-ROC: 0.89660 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.89135\n",
      "\n",
      "Step 1100\n",
      "True: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0]\n",
      "Pred: [1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0]\n",
      "Train loss: 0.00035\n",
      "Train batch AUC-ROC: 0.89843 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.89369\n",
      "\n",
      "Step 1200\n",
      "True: [0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1]\n",
      "Pred: [0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1]\n",
      "Train loss: 0.00047\n",
      "Train batch AUC-ROC: 0.90011 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.89548\n",
      "\n",
      "Step 1300\n",
      "True: [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "Pred: [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      "Train loss: 0.00083\n",
      "Train batch AUC-ROC: 0.90115 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.89704\n",
      "\n",
      "Step 1400\n",
      "True: [1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0]\n",
      "Pred: [1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0]\n",
      "Train loss: 0.00052\n",
      "Train batch AUC-ROC: 0.90230 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.89850\n",
      "\n",
      "Step 1500\n",
      "True: [0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1]\n",
      "Pred: [0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1]\n",
      "Train loss: 0.00059\n",
      "Train batch AUC-ROC: 0.90337 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.89981\n",
      "\n",
      "Step 1600\n",
      "True: [0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "Pred: [0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      "Train loss: 0.00043\n",
      "Train batch AUC-ROC: 0.90423 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90088\n",
      "\n",
      "Step 1700\n",
      "True: [0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "Pred: [0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "Train loss: 0.00041\n",
      "Train batch AUC-ROC: 0.90503 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90189\n",
      "\n",
      "Step 1800\n",
      "True: [0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1]\n",
      "Pred: [0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1]\n",
      "Train loss: 0.00051\n",
      "Train batch AUC-ROC: 0.90578 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90279\n",
      "\n",
      "Step 1900\n",
      "True: [1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0]\n",
      "Pred: [1 1 0 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0]\n",
      "Train loss: 0.00038\n",
      "Train batch AUC-ROC: 0.90638 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90357\n",
      "\n",
      "Step 2000\n",
      "True: [0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0]\n",
      "Pred: [0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0]\n",
      "Train loss: 0.00037\n",
      "Train batch AUC-ROC: 0.90698 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90426\n",
      "\n",
      "Step 2100\n",
      "True: [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1\n",
      " 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Pred: [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1\n",
      " 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Train loss: 0.00122\n",
      "Train batch AUC-ROC: 0.90749 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90483\n",
      "\n",
      "Step 2200\n",
      "True: [0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      "Pred: [0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1]\n",
      "Train loss: 0.00036\n",
      "Train batch AUC-ROC: 0.90789 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90540\n",
      "\n",
      "Step 2300\n",
      "True: [1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "Pred: [1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1]\n",
      "Train loss: 0.00036\n",
      "Train batch AUC-ROC: 0.90833 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90595\n",
      "\n",
      "Step 2400\n",
      "True: [1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "Pred: [1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      "Train loss: 0.00046\n",
      "Train batch AUC-ROC: 0.90872 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90644\n",
      "\n",
      "Step 2500\n",
      "True: [0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1]\n",
      "Pred: [0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 1]\n",
      "Train loss: 0.00024\n",
      "Train batch AUC-ROC: 0.90909 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90689\n",
      "\n",
      "Step 2600\n",
      "True: [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1]\n",
      "Train loss: 0.00046\n",
      "Train batch AUC-ROC: 0.90947 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90736\n",
      "\n",
      "Step 2700\n",
      "True: [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      "Train loss: 0.00034\n",
      "Train batch AUC-ROC: 0.90978 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90773\n",
      "\n",
      "Step 2800\n",
      "True: [0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0]\n",
      "Pred: [0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0]\n",
      "Train loss: 0.00035\n",
      "Train batch AUC-ROC: 0.91007 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90810\n",
      "\n",
      "Step 2900\n",
      "True: [1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1]\n",
      "Pred: [1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1]\n",
      "Train loss: 0.00045\n",
      "Train batch AUC-ROC: 0.91037 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90845\n",
      "\n",
      "Step 3000\n",
      "True: [0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Pred: [0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Train loss: 0.00034\n",
      "Train batch AUC-ROC: 0.91060 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90875\n",
      "\n",
      "Step 3100\n",
      "True: [0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "Pred: [0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      "Train loss: 0.00034\n",
      "Train batch AUC-ROC: 0.91082 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90904\n",
      "\n",
      "Step 3200\n",
      "True: [1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "Pred: [1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1]\n",
      "Train loss: 0.00045\n",
      "Train batch AUC-ROC: 0.91106 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90932\n",
      "\n",
      "Step 3300\n",
      "True: [0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0]\n",
      "Pred: [0 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0]\n",
      "Train loss: 0.00034\n",
      "Train batch AUC-ROC: 0.91124 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90956\n",
      "\n",
      "Step 3400\n",
      "True: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0]\n",
      "Pred: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0]\n",
      "Train loss: 0.00034\n",
      "Train batch AUC-ROC: 0.91145 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.90980\n",
      "\n",
      "Step 3500\n",
      "True: [0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0]\n",
      "Pred: [0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91163 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91004\n",
      "\n",
      "Step 3600\n",
      "True: [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Pred: [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Train loss: 0.00023\n",
      "Train batch AUC-ROC: 0.91179 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91023\n",
      "\n",
      "Step 3700\n",
      "True: [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1]\n",
      "Pred: [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91196 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91046\n",
      "\n",
      "Step 3800\n",
      "True: [1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Pred: [1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      "Train loss: 0.00033\n",
      "Train batch AUC-ROC: 0.91213 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91067\n",
      "\n",
      "Step 3900\n",
      "True: [0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      "Pred: [0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0]\n",
      "Train loss: 0.00034\n",
      "Train batch AUC-ROC: 0.91228 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91086\n",
      "\n",
      "Step 4000\n",
      "True: [0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0]\n",
      "Pred: [0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91245 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91106\n",
      "\n",
      "Step 4100\n",
      "True: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1\n",
      " 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Pred: [0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 1\n",
      " 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      "Train loss: 0.00033\n",
      "Train batch AUC-ROC: 0.91259 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91123\n",
      "\n",
      "Step 4200\n",
      "True: [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "Pred: [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0]\n",
      "Train loss: 0.00033\n",
      "Train batch AUC-ROC: 0.91271 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91139\n",
      "\n",
      "Step 4300\n",
      "True: [1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      "Pred: [1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91285 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91157\n",
      "\n",
      "Step 4400\n",
      "True: [1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1]\n",
      "Pred: [1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1]\n",
      "Train loss: 0.00033\n",
      "Train batch AUC-ROC: 0.91297 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91172\n",
      "\n",
      "Step 4500\n",
      "True: [1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1]\n",
      "Pred: [1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1]\n",
      "Train loss: 0.00022\n",
      "Train batch AUC-ROC: 0.91309 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91185\n",
      "\n",
      "Step 4600\n",
      "True: [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Pred: [1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91323 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91201\n",
      "\n",
      "Step 4700\n",
      "True: [0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0]\n",
      "Pred: [0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91332 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91213\n",
      "\n",
      "Step 4800\n",
      "True: [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0]\n",
      "Pred: [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0]\n",
      "Train loss: 0.00022\n",
      "Train batch AUC-ROC: 0.91342 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91226\n",
      "\n",
      "Step 4900\n",
      "True: [1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Pred: [1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Train loss: 0.00044\n",
      "Train batch AUC-ROC: 0.91353 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91239\n",
      "\n",
      "Step 5000\n",
      "True: [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "Pred: [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0]\n",
      "Train loss: 0.00022\n",
      "Train batch AUC-ROC: 0.91362 \n",
      "Valid true:      [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0]\n",
      "Valid predicted: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0]\n",
      "Validation AUC-ROC:  0.91250\n",
      "Test predicted: [0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0]\n",
      "TIME: 0:51:31.653833\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.datetime.now()\n",
    "losses = []\n",
    "train_aucs = []\n",
    "valid_aucs = []\n",
    "num_steps = 5001\n",
    "frequency = 100\n",
    "mean_losses = []\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    mean_loss = 0.\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        batches, labels = train_batch_generator.next()\n",
    "        feed_dict = dict()\n",
    "        for i in range(comment_size):\n",
    "            feed_dict[tf_data[i]] = batches[i]\n",
    "        train_labels_ = np.asarray(labels).astype('float').reshape(-1,1)\n",
    "        feed_dict[tf_labels] = train_labels_\n",
    "        feed_dict[tf_keep_prob] = 1.\n",
    "        l, update, auc, predictions, _ = session.run([tf_loss, tf_update_oper, tf_auc_roc,\n",
    "                                                   tf_prediction, tf_op],\n",
    "                                                  feed_dict=feed_dict)\n",
    "        mean_loss += l\n",
    "        losses.append(l)\n",
    "        train_aucs.append(auc)\n",
    "        if step % frequency == 0 and step > 0:\n",
    "            mean_loss /= frequency\n",
    "            print ('\\nStep %d' % step)\n",
    "            print ('True:',np.asarray(labels).astype('int'))\n",
    "            print ('Pred:',predictions.astype('int').reshape(-1))\n",
    "            print ('Train loss: %.5f' % mean_loss)\n",
    "            print ('Train batch AUC-ROC: %.5f ' % auc)\n",
    "            mean_losses.append(mean_loss)\n",
    "            mean_loss = 0.\n",
    "            valid_predictions = []\n",
    "            valid_true = []\n",
    "            for _ in range(valid_size):\n",
    "                valid_b, valid_lab = valid_batch_generator.next()\n",
    "                feed_dict = dict()\n",
    "                for i in range(comment_size):\n",
    "                    feed_dict[tf_data[i]] = valid_b[i]\n",
    "                feed_dict[tf_labels] = np.asarray(valid_lab).astype('float').reshape(-1,1)\n",
    "                feed_dict[tf_keep_prob] = 1.\n",
    "                valid_pred, valid_auc, valid_update = session.run([tf_prediction, tf_auc_roc, tf_update_oper], \n",
    "                                                                  feed_dict=feed_dict)\n",
    "                valid_true.append(valid_lab[0])\n",
    "                valid_predictions.append(valid_pred[0])\n",
    "            print('Valid true:     ', np.asarray(valid_true)[:100])\n",
    "            print('Valid predicted:', np.asarray(valid_predictions).astype('int').reshape(-1)[:100])\n",
    "            print('Validation AUC-ROC:  %.5f' % valid_auc)\n",
    "            valid_aucs.append(valid_auc)\n",
    "    \n",
    "    test_predictions = []\n",
    "    for _ in range(test_size):\n",
    "        test_b, __ = test_batch_generator.next()\n",
    "        feed_dict = dict()\n",
    "        for i in range(comment_size):\n",
    "            feed_dict[tf_data[i]] = test_b[i]\n",
    "        feed_dict[tf_keep_prob] = 1.\n",
    "        test_pred = session.run([tf_prediction], feed_dict=feed_dict)\n",
    "        test_predictions.append(test_pred[0])\n",
    "    print('Test predicted:', np.asarray(test_predictions).astype('int').reshape(-1)[:100])\n",
    "    test_data_.insert(loc=0, column='Insult', value=np.asarray(test_predictions).astype('int').reshape(-1))\n",
    "    test_data_.to_csv('./data/insult_subm_v5.csv', index=False)\n",
    "    test_data_ = test_data_.drop('Insult', axis=1)\n",
    "t1 = datetime.datetime.now()\n",
    "print ('TIME:', t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFLI4W5mlkL/H7uDjsafRbUiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27dee586ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27dee4b3cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEWCAYAAACdaNcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VdW99/HP70w5mYGEeQpCBIIgCKJUqzhWRYFWa0Wt\nfdTWqy21WqvVW+u93vpcvbZeh6rXx6nWawXr3MEJEYc6MYZ5DgGSQObpJCdnXM8fZycNIZAQEk7O\nzu/9euXFOXv8LYSvi7X3XluMMSillLIXR7wLUEop1f003JVSyoY03JVSyoY03JVSyoY03JVSyoY0\n3JVSyoY03JVSyoY03FXCEZGPRaRaRJLaLPthm+1mi0hRq+8iIjeLyAYRaRCRIhF5VUQmH+I8s0Uk\nKiI+EakXka0icm2bbUREbheR7SLiF5E9InJ/69qs7WaKyDsiUiMiVSKyvO2xlOpOGu4qoYhIDvBN\nwABzj3D3R4GfATcDA4DjgbeAOYfZp8QYkwZkALcCz4jI+FbrHwNuAK4B0oELgXOAP7eqeRbwEfAJ\nMA7IAm4CLjjC+pXqNFe8C1DqCF0DfAV8DfwAeLUzO4lILvATYJYxZnmrVX/qzP4m9ij3OyJSBUwB\ntlrH/HGbY24UkUuBHSJytjHmI+C3wB+NMf/V6pCrgO915txKdYX23FWiuYZYIP8J+JaIDO7kfucA\nRW2CvdNExCEic4FsYMfhjmmM2Uvsf0DniUgKMAt4rSvnVaqrNNxVwhCR04HRwJ+NMauAncCVndw9\nC9jXhdMOE5EawA+8CfzcGLPGWpd9mGPus9b3J/b3rCvnVqrLNNxVIvkB8IExpsL6/rK1DCAMuNts\n7wZC1udKYOihDiwio6wLpz4R8bVaVWKM6UdszP0x4OxW6yoOc8yh1vpqIHq4cyvVEzTcVUIQkWTg\ncuBMEdkvIvuJXeA8UUROBPYAOW12GwPstj4vBUaIyIz2jm+M2WOMSWv+aWd9APglMFlE5luLPwJG\nisjMNrWOBE4FlhpjGoEvgUuPuNFKHQUNd5Uo5gMRIA+Yav1MBD4jNg7/CnCtdcuhiMjxxMJ/MYAx\nZjvwJLDIusXRIyJeEblCRO7sTAHGmCDwEHCP9X0b8BTwJxE5VUScIjIJeB340BjzobXrHcD/sW6Z\nzAIQkRNFZPFR/64odQga7ipR/AD4g9XD3t/8AzwOXEWsZ34n8AegFngH+CPwdKtj3Gxt/wRQQ2zM\n/tvAX4+gjueBUSJyifV9IfAs8BLgA94DPqZVT90Y8wWx4ZyzgQLrjpunrRqV6hGiL+tQSin70Z67\nUkrZkIa7UkrZkIa7UkrZkIa7UkrZUNzmlsnOzjY5OTnxOr1SSiWkVatWVRhjBna0XdzCPScnh5Ur\nV8br9EoplZBEZHfHW+mwjFJK2ZKGu1JK2ZCGu1JK2ZCGu1JK2ZCGu1JK2ZCGu1JK2ZCGu1JK2ZC+\nIFsp1esYYxCRg5YHw1FcDsHhkAO2rW4MkeJx4nU7D9i2tK6JZI+T7LSklm1r/SH21TbhdTsZk50K\nQCgSpaw+wP5aPyBMH90fYwx1/jCl9U2U1jURikQ5a/wgIlFDuS9AaV2A0romGoNh5kweRjASO19p\nXRNldQFq/SHmnhhbXlYXoKy+ibL6AGV1AWaNzWLmmAE9+nuo4a5ULxGJGhzCAaFmjKGyIUiKx0mK\n559/XZtCEXaW+8jwuhk5IKVl2/11TRSUN5DscXLSqP4A1DWFKKxoYFdFAw4RLjlxGKFIlKJqf8vy\nQDjKv5xxHNWNQQorG9lT1UBhRSP1TWF+evY4KhsC7K5sZHdlI3uqGin3Bbh21ijCoSDFlfUUV/ko\nqa5nf3U98yYPJtProLTGR2lNA2U1DZTWNjJzdAaj+3sor22koq6ByvpGKusaGdnPzeSh6dT4/NQ0\n+Knx+any+cn0CDNGZVDrD1DX0ES9P4A/EMRBlOkj0vE1BfD5A/ibAkSjEVxEGJuVTGMgSFMwSDAU\nwmGiOIgyJCOJQDBIIBgCE8FJFMFQnOQgEgkTDodxEcFBFCdRVjgAooi1fzoGB1E2YnASW5aKYZy1\n/f43ozjEkEyUsUTJJYoDA+/HluVgOM5a5sCwYc/3YczDPfrnKW7zuc+YMcPoE6oqXsKRKLX+EFlW\njw5i4binqpGiaj+nHpeF0+odltY1sa6olsKKBi6fMZLMFDe1jSE2ltSyoaSWXRUNXH/6GIb3S2Fr\naT0bS2rZvK+OnWUNXHf6GEZnpbB5Xx2b99WzuaSWrfuqmZOXxenHZbKrtJrC0hr2ltewp6KWnEwX\n86cMpLiqjtLKekpr6ggEmnAT4VsTBlBR66Oq3kd9gx83sUCaPDSVuoZGfI1+opHYMjdhhqW7aGwK\nEAkHcdG8PEKyMwrRME4TwSWRluM4raBqDjkXEZwS+7V539h2sc8O6T3vgojgIGIcRMWBESeIExxO\nQlEhGAVxOBGHE4fDiThdhI3gC0RxuFw4ndaPy40RB+W+MG63C7fLhdvlxO1243Q6KKoJ4Ha58bhd\neNxukjxuPC4Xu6r8uFwuktxuvB43Xo8Lb5KHvdUBQlHwJrlJ9nhISXKTkuQmOcmNc8wZkHtul9oq\nIquMMe2+LvKA7TTcVTy198/vaNSweX8daUkuRmeltmy3s9zHFzsryfC6mT9tOMYYiqr9fFVQyeo9\n1YgI/3f+Ceyva2LV7mpWFlbzVUElTaEIf7xuJlv217N6TzVrdleTX1iGlwB3njuahoYGCkrK2VNW\nRaipEa8EmTLYQ4YrQnlVNcGmRpIJ4JUgSYTISjIEA36SCOGRcOxXQnglhJsQSYRIljBOEyJJYuuS\nCOOxtnfQc3/nIuIiIi6aog6MuMDpxuF043R5iDpcVDRGcLjcuFxJuD0ekpKScLk87KoO4nS58HqS\nSPZ6SPF68Sa52by/AXG6SU32kpaSTHqKF2+Sl42lDURxkZGaTGZqMhmpyThdbnZUNBGICv3SkhmQ\nnkJyUhKIg311QepDQnZmCpmpKTidLnC4qAtEqQ0aBmWmkuTxWKHsImiEhmCUfmnJiMPVEtZGHISi\ngsfjAUfsGIgD2hnCsSsNd3XMNYUifFVQSd6wDAalewGobQzx8bYyPtlazjkTBzNnylAqfAGWbSnj\ns+0VLNlUysVThvLz84/ns+0V/GN7BZ/vqKCyIUA/d5R7zh/Ful0lbNmzn0BDHckSIJUmzhyTQnFp\nJUF/PSk0kSoBkmminyuEM+InhQBpjiBJpokUAngJ4pUAyQRJliBOol1qYxAXEUcSOD2I24vb46XM\nDwHjxp2UjNebTEpqKl5vMrtrw9SFHKSnppKZnk5meipOt5fi+ijlfkN2ZhrZ/dLxJnnB6aEmAPt9\nEYZkZZCZmoq4POD0EMRJld8wsF86TpcbnLHlOGJB7nR5wOkGh7PjBqiE163hLiIXAI8CTuBZY8wD\nbdb3J/ZuybFAE3CdMWbD4Y6p4d67RKPmgItUABtLalm6uYwrTh7JoAwvkajhq4JK3s4v5qMt5fz6\n4omclzeYj7eW8/f1+1i2pYzGYIRvTRrMN8b047MNBRTsKSLd1NNffGTQyKQBhtqaCjJoZKA7gCdc\nRzp+0sRPGn4yHE1kOprwRhuOKICjDg++qIewMwVHUiqelDS8KemEnclsrYqQlJxG/8xM+vfLxJWU\nStTpZWN5kPT0DIZl98fjTQFXMri9lPqFtLR0UlPTwZ1sLU8GlxcceoOZiq9uC3cRcQLbgPOAImAF\nsMAYs6nVNr8FfMaYe0VkAvCEMeacwx1Xw/3Y27K/jq92VnL1qaNxOR2EI1GWbinj2c8KWFFYzRs/\n/gZjs9N4e20xr6zYy8aSOgC+M204A5MifLlhK9JQzghPAynhagZQzyCnj/RoHYNdDeSkNGEaKuhH\nPRk0HnZMNupwI8n98JFKRciDJ7Uf6ZkDSM/sjyRlUBv1srteGDoom+wB/RFPKnjSCDu9VARdDM7K\nQpLSwJ0CntRYz1WpPqCz4d6Zu2VmAjuMMQXWgRcD84BNrbbJAx4AMMZsEZEcERlsjCk98tJVZwXD\nUWr8wZYhEIj1th//aAer91Tz/i1nkJns5qMtZTz9aQFf76oCYGi/ZHaW+/jfL3dTUetjsFRxilTy\nwlOfM9xZQ7ap4pfJPnIH1xOqLiZ7Ux0pEoidoPn6o5WlIfEQTRuAJ30gkppNcXAkRSadYUOHMSBr\nMKQMgOT+BFwZNLnSyeyfDd5MHC4viJAOpLfTtkxgSjvLXcCQ7vntU8rWOhPuw4G9rb4XAae02WYt\n8B3gMxGZCYwGRgAHhLuI3ADcADBq1Kgultz3VPgCVDUEOX5wLAajUcMba4r5xatrEYGN936LgvIG\nHl26nSWbShEBY+DJZTtYtbWQpvJdTE6r46qcRsqKthNe/AjfkEoWuKrp561G2lzgi7hScGYMg/Sh\n7Eg+mb3J2YwalUNyv8GQkg2pAwl7ByBp2biT0g64mDXc+mkriX/+f0Ep1fO66z73B4BHRSQfWA+s\nASJtNzLGPA08DbFhmW46t20EwhEC4SgZ3li3OBo1/Onr3fz67Y0AFD4whxWFVfzHXzexvrg2tpOJ\nctuzf6emaCsTPWW8PraJoZESaku2MWJ5Benij6VqCNgPTS4PtZ4hpA3KIXXgLMgcCRnDKZNsMoeM\nJqn/CJxJ6S2BPe4QteoDEkr1bp35O1oMjGz1fYS1rIUxpg64FkBi97XtAgq6qcY+YWVhFbe8kk+G\n1807P/smO8rqufP19azcXd2yza0vLGPftpWclVzC48dXk167lZSa7XjLQuCxNtqfRKRfDrX9RlE7\nZDZpOeORfqNiId5vFN6ULLzt3DY26Bi1Uyl1bHQm3FcAuSIyhlioXwFc2XoDEekHNBpjgsAPgU+t\nwFdthCJRfvfBVlI9Lm4+J5dgOMojH27jqU92EjWQ4Q3x6IfbeW7ZRqZ7dvPXabWklK8hqXwdIwor\nYiEeASoHEh44ic2ZMxg9fjIZQ8fDgOMgYzhOh4OJ8W6oUiquOgx3Y0xYRBYC7xO7FfJ5Y8xGEbnR\nWv8UMBH4o4gYYCNwfQ/WnDCaQhFEIMkVu/+4vD7Av/zvSlbvqcEh8O1pw/nJy6tZV1TLNdMyyald\ngWvP50z7dDsL3XtwmihshlDGaLZlTSMjbyYZo0+CIZMhfTAuYHJ8m6iU6qX0IaYesqeykTN+u4y5\nJw7jsQXT2FZaz3UvrKDCF6ApFAUMp3iL+Qar+X7WdgZU5YOJ0EAyTYOmkjX+NBhxMoyYAanZ8W6O\nUqqX6M5bIdUR2l3ZwIKnvwLg612VfFVQyY9eXEmyS/j7XAcFy15kSsMXDKYmtoPnRDj9Vsg9j9Th\nM0h16n8WpdTR0RQ5SpGo4T/f2czJOf254ISh7Kv1c+UzX9MYipDudVFa18T9z73Cr1OX8x3P17j+\nXkKOM5mtA2bR/7RL8Yw/D9IHx7sZSimb0XA/Sg+8u5nn/rGL1XuqOTlnAFc/+zV1/hCv/GAiS/73\nv5jj+YhxjhJM2IXknAuTf4Nz/IXkeVLjXbpSysY03I/CW2uKeeazXQBkJrv5wR+WY6p3s2RyPkMW\nX0ee8bEjdQqh2b/APfnbsac1lVLqGNBwPwLrimoY2T+F/qketpXWc9cb65k5ZgBFVY1Ubvuaf3H9\nnTnu5Ti2CpxwKcxayLih7T1Er5RSPUvDvZPW7Knm209+wfdmjOTXl+Rx00urSE1y8uScbNb/v+s5\nK2ktIVcajpk/gVNuhMz2HsJXSqljQ8O9E5pCEW57dS0AUWP45evr2FXhY8kZu8h+8Vq+mRRh68Rf\nMH7Oz8CbEedqlVJKw71Tnvx4JwXlDQC8lV/MoEgZnwx9mZFffw1jzsQ19/eM7z86zlUqpdQ/6ZsH\nOrC/tomnP93JxVOGAobv8iEfJt/JiIaNcPHDcM3boMGulOpltOfehjGGP3xeyHl5gxk5IIXfvr+V\naBTuPHskl26+hbOcawmM+CbynSc01JVSvZaGexufbq/gP/62iVAkymnjsnljTRE3z8pmxN8WMMy1\nga3T7mH8JT/vUy/kVUolHg33Np7+dCcA4ajhvr9v4rhkPzcX/RwqtuK4/I+Mn3hJnCtUSqmOabi3\nsqG4ls93VALwwaZSSvfu5P2sh3BWlcKVi2HcuXGuUCmlOkfDvZWnPy0g1eOkIRihumgrbybfT0bY\nD99/E0bPind5SinVaXq3jKWoupG/r9/HlaeMYpwU8arnXrLcQeQHf9VgV0olHA13ywufFyLA9dPS\nWeS5DwHc178Lw6bFuzSllDpiOiwD+AJhFq/Yy5wpQxny5b1EnX6qr/4AGZwX79KUUqpLtOcOvLdh\nP75AmIUjdsL6V3Gc8Quyjjsp3mUppVSX9elw31nuIxyJ8taaYsb3F8Yt/zcYOBFO/3m8S1NKqaPS\nZ4dlVhRW8d2nvuTms8fxxc4K3hj9JrK/GK5fAi5PvMtTSqmj0md77q+tLALg5eV7mMZWTtz/Wmyq\n3pEnx7kypZQ6en225750SykA9T4fj6Q+h6SNhLPvjnNVSinVPfpkuO+vbaLCFwRgoestRkaK4JI3\nICktzpUppVT36JPDMsu2lgEwQfZwo/Ov+PMuh3HnxLkqpZTqPn0y3D/bXo7XBQ+4n6aGVJIv/q94\nl6SUUt2qz4W7MYavCqq4YWwNUx0FlJ98B6QMiHdZSinVrfpcuG8v81HVEOQCdz6Ik7yzr4p3SUop\n1e36XLh/VRCb0ndczT9g1Knaa1dK2VKfDPeTMuvxVGyC4y+IdzlKKdUj+lS4G2P4uqCKq/pvji0Y\nf2F8C1JKqR7Sp8J9R5mPyoYg34isgAFjITs33iUppVSP6FPhvrywilT8DKlcob12pZSt9alw/6qg\nijmpW5FoUMfblVK21mfC3RjD8l2VfCd1PXgzY3fKKKWUTfWZuWWKa/yU1fk5ka/h+PPA6Y53SUop\n1WP6TM89f28NU2UnycEqHZJRStme7XvuNY1BfvXWBtwO4VvuNRhxIrnnxrsspZTqUbYP9//5ZCd/\nX7cPgI9T85ERsyC5f5yrUkqpnmX7YZmC8gYAhlNOTqQQxuuQjFLK/joV7iJygYhsFZEdInJnO+sz\nReSvIrJWRDaKyLXdX2rX7K6MhfvZzjWxBcfr/e1KKfvrMNxFxAk8AVwI5AELRCSvzWY/ATYZY04E\nZgMPiUiveMt0YWUjAOc6VhPIPA6yx8W5IqWU6nmd6bnPBHYYYwqMMUFgMTCvzTYGSBcRAdKAKiDc\nrZV2UTAcJRU/pzo24ZyovXalVN/QmXAfDuxt9b3IWtba48BEoARYD/zMGBNteyARuUFEVorIyvLy\n8i6W3HnVDbH3pJ7uWE+ShHFNuKjHz6mUUr1Bd11Q/RaQDwwDpgKPi0hG242MMU8bY2YYY2YMHDiw\nm059aAUVsfH2cx2rqTUpMPKUHj+nUkr1Bp0J92JgZKvvI6xlrV0LvGFidgC7gAndU2LX7Sz34SDK\nWc58Vrpn6FOpSqk+ozPhvgLIFZEx1kXSK4C/tNlmD3AOgIgMBsYDBd1ZaFfsqmggV4rIljq8E78V\n73KUUuqY6fAhJmNMWEQWAu8DTuB5Y8xGEbnRWv8U8BvgBRFZDwjwS2NMRQ/W3Sl7qxqZkVEDATjt\n1G/EuxyllDpmOvWEqjHmHeCdNsueavW5BDi/e0s7enurGpmVXAUBoH9OvMtRSqljxtZPqO6t9jPG\nWQlJmTrlgFKqT7FtuDcEwlQ1BBlu9kP/USAS75KUUuqYsW24762OPZk6ILhPh2SUUn2OfcO9yo8Q\nJdVfrOGulOpzbBzujQyiBkckoOGulOpz7Bvu1Y3keipjXzTclVJ9jH3DvcrPiak1sS/9cuJai1JK\nHWu2Dfei6kbGJ1UAAv1Gdri9UkrZiW3Dvbjazygph4zh4EqKdzlKKXVM2TLcGwJh6gNhBkf363i7\nUqpPsmW4l9UHAOgXKIH+o+NcjVJKHXv2DPe6JpIIktxUpj13pVSfZMtwL60PMEKsNz1puCul+iBb\nhntZXROjpCz2RcNdKdUH2TLcy+sDjHFqz10p1XfZMtxL65o43lMJ7hRI7fl3tSqlVG/TqZd1JJqy\n5p575mid6lcp1SfZsudeVh9gOHqnjFKq77JluJfW+RkY1nnclVJ9l+3C3R+M4G6qJinq1weYlFJ9\nlu3Cvaxeb4NUSikbhntAw10p1efZL9zrAoxsDvd+OiyjlOqbbBfupXVNjJQyoqmDwJMS73KUUiou\nbBfuZfUBRjvKEB2SUUr1YTYM9yZyHOUa7kqpPs124V5Z62MQlXoxVSnVp9ku3KV2L06iGu5KqT7N\nduGe5CuKfdBwV0r1YbYK96ZQhKzQvtgXfTpVKdWH2Srcy60HmCION6QPjXc5SikVN7YK97L6JkZK\nKYHUEeBwxrscpZSKG3uFe12AkVJOVJ9MVUr1cbYK91Lr3amuATnxLkUppeLKVm9iqq0up580EB04\nNt6lKKVUXNmq5051IQAO7bkrpfo4W4W7p35v7IPe466U6uNsFe4pDc0PMOkFVaVU32arcO8XKKHB\nkQHezHiXopRScdWpcBeRC0Rkq4jsEJE721l/u4jkWz8bRCQiIgO6v9zDGxjeR4132LE+rVJK9Tod\nhruIOIEngAuBPGCBiOS13sYY81tjzFRjzFTgLuATY0xVTxR8KKFIlKHR/TSkjDiWp1VKqV6pMz33\nmcAOY0yBMSYILAbmHWb7BcCi7ijuSFTUNTJcKghl6Hi7Ukp1JtyHA3tbfS+ylh1ERFKAC4DXD7H+\nBhFZKSIry8vLj7TWw/JXFuGRCJHMUd16XKWUSkTdfUH1EuDzQw3JGGOeNsbMMMbMGDhwYLeeOFJZ\nAEA0U3vuSinVmXAvBka2+j7CWtaeK4jDkAxARdoErgn+ksjQafE4vVJK9SqdCfcVQK6IjBERD7EA\n/0vbjUQkEzgTeLt7S+ycWpPCp9ET8ab3j8fplVKqV+lwbhljTFhEFgLvA07geWPMRhG50Vr/lLXp\nt4EPjDENPVbtYTQGwwCkemw1XY5SSnVJp5LQGPMO8E6bZU+1+f4C8EJ3FXakGgJWuCdpuCullG2e\nUG0IRgBITdKXdCillH3CPRDGIZDs1nBXSinbhLsvECbV40JE4l2KUkrFnW3CvTEQIUWHZJRSCrBR\nuPuCYb2YqpRSFtuEe6M1LKOUUspG4d4QiOidMkopZbFNuPsCYdJ0WEYppQAbhXtjMEyKDssopRRg\no3D3BSJ6QVUppSy2CffGYJhUj465K6UU2CTco1FDY1B77kop1cwW4d5gzQipF1SVUirGFuHeaE0a\npk+oKqVUjC3C3RfQnrtSSrVmi3BvDFg9d70VUimlAJuEu6/lRR06LKOUUmCTcG/QYRmllDqAPcLd\nultGh2WUUirGFuH+4eYyQHvuSinVzBbh/s76fQAMSk+KcyVKKdU72CLcL5g0hLEDU3E49BV7SikF\nNgn3+kCYNK873mUopVSvYYtwbwiESdPbIJVSqoVtwj3ZrRdTlVKqmS3CvSkUIUWn+1VKqRa2CPfG\noIa7Ukq1Zotw9wcjJGu4K6VUi4QPd2MMjToso5RSB0j4cA9GokSiRqceUEqpVhI+3P3WizqS3dpz\nV0qpZokf7qHmudw13JVSqlnCh3vzdL8pOmmYUkq1SPhwr/XHwj0zWacfUEqpZgkf7nVNIQAyvNpz\nV0qpZokf7n4r3LXnrpRSLRI/3JtiwzLp2nNXSqkWCR/uvuZwT9Keu1JKNetUuIvIBSKyVUR2iMid\nh9hmtojki8hGEfmke8s8NH8wjAh43Qn//ymllOo2HY5liIgTeAI4DygCVojIX4wxm1pt0w94ErjA\nGLNHRAb1VMFtNQYjJLudiOhbmJRSqllnurszgR3GmAJjTBBYDMxrs82VwBvGmD0Axpiy7i3z0J79\nxy4aradUlVJKxXQm3IcDe1t9L7KWtXY80F9EPhaRVSJyTXcVqJRS6sh11y0mLmA6cA6QDHwpIl8Z\nY7a13khEbgBuABg1alQ3nRq+MTar246llFJ20JmeezEwstX3Eday1oqA940xDcaYCuBT4MS2BzLG\nPG2MmWGMmTFw4MCu1txiV0UDAF/srDzqYymllJ10JtxXALkiMkZEPMAVwF/abPM2cLqIuEQkBTgF\n2Ny9pR6suNoPwEWTh/T0qZRSKqF0OCxjjAmLyELgfcAJPG+M2SgiN1rrnzLGbBaR94B1QBR41hiz\noScLB6jxBwG45dzje/pUSimVUDo15m6MeQd4p82yp9p8/y3w2+4rrWN11qRhGV59gEkppVpL6Cd/\nKnwBQGeEVEqpthI63PfV+slO8+jLsZVSqo2EDvfy+iDZaUnxLkMppXqdhA73yoaAhrtSSrUjocO9\nuiFI/1RPvMtQSqleJ6HDvcYfon+KXkxVSqm2Ejbco1FDrT9EP71TRimlDpKw4V7fFMYYyEzRYRml\nlGorYcO9+elU7bkrpdTBEjbcmx9g6qdj7kopdZCEDfddFY0ApOvUA0opdZCEDfdAOPb2pVEDUuJc\niVJK9T4JG+61/hCg88oopVR7Ejbc6/xhPE4HXnfCNkEppXpMd71m75ir9YfISHYjIvEuRaleLRQK\nUVRURFNTU7xLUUfA6/UyYsQI3O6ujU4kbLgvWr4n3iUolRCKiopIT08nJydHO0MJwhhDZWUlRUVF\njBkzpkvH0DENpWyuqamJrKwsDfYEIiJkZWUd1b+2Ejrc05MS9h8eSh1TGuyJ52j/myVkuNc2xu6U\nqQ+E41yJUkr1TgkZ7v5Q7B73uy6cEOdKlFIdqaysZOrUqUydOpUhQ4YwfPjwlu/BYLBTx7j22mvZ\nunXrEZ/74osv5vTTTz9g2dVXX81bb73V8j0cDtOvX7+W71u2bOHCCy8kNzeXk046iSuuuIKysrKD\njn311VczZswYpk6dyoknnsiyZcta1gUCAX76058yduxYcnNzmT9/PiUlJS3rS0pKuPzyyxk3bhzT\np09nzpw57Nix44jbdzgJOa7R/ACTvqhDqd4vKyuL/Px8AP793/+dtLQ0fvGLXxywjTEGYwwOR/v9\nzT/84Q/ceYFmAAAQTUlEQVRHfN6qqirWrVuH1+tlz549jBo1qsN9GhsbmTNnDr///e+56KKLAFi6\ndCmVlZUMGjTooO0ffvhh5s+fz5IlS/jxj3/M5s2bAfjlL39JIBBg27ZtOJ1OnnnmGS699FK+/PJL\njDHMnz+fG264gT//+c8ArFmzhtLSUsaNG3fE7TyUhAz3plAUAK9b352q1JG4968b2VRS163HzBuW\nwb9dMumI99uxYwdz585l2rRprFmzhiVLlnDvvfeyevVq/H4/3/ve97jnnnsAOP3003n88cc54YQT\nyM7O5sYbb+Tdd98lJSWFt99+u93gfe2115g/fz6ZmZksXryYO+64o8OaXnrpJc4888yWYAc455xz\nOtxv1qxZFBcXA1BfX89LL71EYWEhTmcso370ox/x/PPP88knnxAIBEhLS+OHP/xhy/7Tpk3r8BxH\nKiGHZZp77kmuhCxfKWXZsmULt956K5s2bWL48OE88MADrFy5krVr17JkyRI2bdp00D61tbWceeaZ\nrF27llmzZvH888+3e+xFixaxYMECFixYwKJFizpVz4YNG5g+ffoRt+O9995j/vz5AGzfvp0xY8aQ\nlpZ2wDYzZsxg48aNXT7HkUrInnsgrD13pbqiKz3snjR27FhmzJjR8n3RokU899xzhMNhSkpK2LRp\nE3l5eQfsk5yczIUXXgjA9OnT+eyzzw46bklJCXv27GHWrFkARKNRtmzZwoQJE9q9C6Wrd6bceuut\n3HHHHRQXF/P111936Rg9JSG7vk3WBdUknXpAqYSWmpra8nn79u08+uijfPTRR6xbt44LLrig3fu8\nPZ5/vqDH6XQSDh9819wrr7xCRUUFOTk55OTksGfPnpbee1ZWFtXV1S3bVlVVkZ2dDcCkSZNYtWpV\nu7Vec801TJ06lblz57Yse/jhh9m2bRv33Xcf119/PQC5ubns2rULn893wP6rVq1i0qRJhz1Hd0rI\ndAw0j7m7tOeulF3U1dWRnp5ORkYG+/bt4/333+/ysRYtWsSHH35IYWEhhYWFLF++vCXcZ8+ezeLF\niwmFYrdUv/DCC5x11lkAfP/73+fjjz/mvffeaznWsmXL2Lx5My+++CL5+fn85S9/Oeh8t9xyC42N\njSxdupT09HSuvPJKbr/9dqLRWFY9//zzRKNRzjzzTM4//3zq6uoOGE5au3Ytn3/+eZfb257EDHdr\nWEZ77krZx0knnUReXh4TJkzgmmuu4bTTTuvScXbu3Mm+ffsOGO7Jzc3F6/WyatUq5s+fzymnnML0\n6dOZOnUqK1as4P777wcgJSWFv/3tbzz88MPk5uaSl5fHM88809KzPxQR4e677+bBBx8E4MEHH8Th\ncJCbm8u4ceN46623eP3111u2ffvtt3nnnXcYO3YskyZN4u6772bIkCFdau8hazLGdOsBO2vGjBlm\n5cqVXdr39VVF3PbqWj65fTajs1I73kGpPmzz5s1MnDgx3mWoLmjvv52IrDLGzDjELi0Ssuv7H3+L\nXUHXC6pKKdW+hAv3ZVvKWl7UkeLRcFdKqfYkXLg3BiMtn/X9qUop1b6EC3ed3E4ppTqWeOEe7wKU\nUioBJFy46zS/SinVsYQL90Ao0vFGSqle46yzzjrogaRHHnmEm2666bD7Nc/NUlJSwmWXXdbuNrNn\nz+ZQt1RXVFTgdrt56qmn2j1usxdeeIGFCxe2fH/xxRc54YQTmDx5MtOmTeN3v/tdu8d3Op1MnTqV\nE044gUsuuYSampqWdRs3buTss89m/Pjx5Obm8pvf/IbWt52/++67zJgxg7y8PKZNm8Ztt912mN+J\nrkm4cA9H43NfvlKqaxYsWMDixYsPWLZ48WIWLFjQqf2HDRvGa6+9dsTnffXVVzn11FM7PWkYxEL3\nkUce4YMPPmD9+vV89dVXZGZmtrttcnIy+fn5bNiwgQEDBvDEE08A4Pf7mTt3LnfeeSdbt25l7dq1\nfPHFFzz55JNAbHKyhQsX8tJLL7Fp0yZWrlzZrVP9Nku4icPCEQ13pbrs3Tth//ruPeaQyXDhA4dc\nfdlll3H33XcTDAbxeDwUFhZSUlLCN7/5TXw+H/PmzaO6uppQKMR9993HvHnzDti/sLCQiy++mA0b\nNuD3+7n22mtZu3YtEyZMwO/3H/K8ixYt4qGHHuLKK6+kqKiIESNGdNiU+++/n9/97ncMGzYMgKSk\nJH70ox91uN+sWbNYt24dAC+//DKnnXYa559/PhB76vXxxx9n9uzZ/OQnP+HBBx/kV7/6FRMmxF42\n5HQ6O/xXTFdoz10p1aMGDBjAzJkzeffdd4FYr/3yyy9HRPB6vbz55pusXr2aZcuWcdttt3G4p+b/\n53/+h5SUFDZv3sy99957yAm49u7dy759+5g5cyaXX345r7zySqdq7cp0vJFIhKVLl7ZMKLZx48aD\njjF27Fh8Ph91dXU65e+hRKyJeJRSXXCYHnZPah6amTdvHosXL+a5554DYm9g+td//Vc+/fRTHA4H\nxcXFlJaWHnKelU8//ZSbb74ZgClTpjBlypR2t3vllVe4/PLLAbjiiiu47rrrDjuu3ZUpf/1+P1On\nTqW4uJiJEydy3nnnHfExelKneu4icoGIbBWRHSJyZzvrZ4tIrYjkWz/3dH+pMSEdllEq4cybN4+l\nS5eyevVqGhsbW3quf/rTnygvL2fVqlXk5+czePDgdqf5PVKLFi3ihRdeICcnh7lz57Ju3Tq2b98O\nxMbKW7+7tTNT/u7du7flva/NF2ibx9x3796NMaZlzD0vL++gYxQUFJCWlkZGRkbvmfJXRJzAE8CF\nQB6wQETy2tn0M2PMVOvnP7q5zhZhq+d+wvCMnjqFUqqbpaWlcdZZZ3HdddcdcCG1traWQYMG4Xa7\nWbZsGbt37z7scc444wxefvllIDaE0jzO3dq2bdvw+XwUFxe3TPl71113tVxYPfPMM3nppZeAWO/7\nz3/+c8uUv3fddRe33347+/fvByAYDPLss88ycuRI8vPzyc/P58YbbzzgfCkpKTz22GM89NBDhMNh\nrrrqKv7xj3/w4Ycftpzj5ptvbnnN3+23385//ud/sm3bNiD2IpG2d/R0h8703GcCO4wxBcaYILAY\nmNfBPj3Gaf3zaf7U4fEqQSnVBQsWLGDt2rUHhPtVV13FypUrmTx5Mi+++GLLRcZDuemmm/D5fEyc\nOJF77rmn3bHrRYsW8e1vf/uAZZdeemlLuD/66KO88cYbTJ06lVNPPZXvfve7nHHGGQBcdNFFLFy4\nkHPPPZdJkyZx0kknUVfX8Ttnp02bxpQpU1i0aBHJycm8/fbb3HfffYwfP57Jkydz8sknt9xuOWXK\nFB555BEWLFjAxIkTOeGEEygoKOjwHEeqwyl/ReQy4AJjzA+t798HTjHGLGy1zWzgDaAIKAZ+YYzZ\neLjjdnXK34ZAmMeWbufW847XWSGV6gSd8jdxHc2Uv911QXU1MMoY4xORi4C3gNy2G4nIDcANAKNG\njerSiVKTXNx1kf5BVUqpw+nMsEwxMLLV9xHWshbGmDpjjM/6/A7gFpGDXl1ijHnaGDPDGDNj4MCB\nR1G2Ukqpw+lMuK8AckVkjIh4gCuAA14iKCJDxLqXSERmWset7O5ilVJdE683rqmuO9r/Zh0Oyxhj\nwiKyEHgfcALPG2M2isiN1vqngMuAm0QkDPiBK4z+aVKqV/B6vVRWVpKVldWl+7nVsWeMobKyEq/X\n2+VjJOQ7VJVSnRcKhSgqKuqW+8fVseP1ehkxYgRu94EvJTrWF1SVUr2U2+1mzJgx8S5DHWMJN7eM\nUkqpjmm4K6WUDWm4K6WUDcXtgqqIlAOHn0ji0LKBim4sJxFom/sGbXPfcDRtHm2M6fBBobiF+9EQ\nkZWduVpsJ9rmvkHb3DccizbrsIxSStmQhrtSStlQoob70/EuIA60zX2Dtrlv6PE2J+SYu1JKqcNL\n1J67Ukqpw9BwV0opG0q4cO/oZd2JRESeF5EyEdnQatkAEVkiItutX/u3WneX1e6tIvKtVsuni8h6\na91j0kun/hORkSKyTEQ2ichGEfmZtdzObfaKyHIRWWu1+V5ruW3b3ExEnCKyRkT+Zn23dZtFpNCq\nNV9EVlrL4tdmY0zC/BCbcngncBzgAdYCefGu6yjacwZwErCh1bIHgTutz3cC/2V9zrPamwSMsX4f\nnNa65cCpgADvAhfGu22HaO9Q4CTrczqwzWqXndssQJr12Q18bdVt2za3avvPgZeBv9n9z7ZVayGQ\n3WZZ3NqcaD33XvWy7qNljPkUqGqzeB7wR+vzH4H5rZYvNsYEjDG7gB3ATBEZCmQYY74ysT8ZL7ba\np1cxxuwzxqy2PtcDm4Hh2LvNxlhvKSMW7m7AYOM2A4jICGAO8GyrxbZu8yHErc2JFu7Dgb2tvhdZ\ny+xksDFmn/V5PzDY+nyotg+3Prdd3quJSA4wjVhP1tZttoYn8oEyYIkxxvZtBh4B7gCirZbZvc0G\n+FBEVknsfdEQxzbrfO69mDHGiIjt7lUVkTTgdeAWY0xd6yFFO7bZGBMBpopIP+BNETmhzXpbtVlE\nLgbKjDGrRGR2e9vYrc2W040xxSIyCFgiIltarzzWbU60nnuHL+u2gVLrn2ZYv5ZZyw/V9mLrc9vl\nvZKIuIkF+5+MMW9Yi23d5mbGmBpgGXAB9m7zacBcESkkNnR6toi8hL3bjDGm2Pq1DHiT2DBy3Nqc\naOHe4cu6beAvwA+szz8A3m61/AoRSRKRMUAusNz6J1+diJxqXVW/ptU+vYpV33PAZmPMf7daZec2\nD7R67IhIMnAesAUbt9kYc5cxZoQxJofY39GPjDFXY+M2i0iqiKQ3fwbOBzYQzzbH+wrzkf4AFxG7\ny2In8Kt413OUbVkE7ANCxMbWrgeygKXAduBDYECr7X9ltXsrra6gAzOsP0g7gcexnjzubT/A6cTG\nJdcB+dbPRTZv8xRgjdXmDcA91nLbtrlN+2fzz7tlbNtmYnfwrbV+NjZnUzzbrNMPKKWUDSXasIxS\nSqlO0HBXSikb0nBXSikb0nBXSikb0nBXSikb0nBXfYqI/MqanXGdNXvfKSJyi4ikxLs2pbqT3gqp\n+gwRmQX8NzDbGBMQkWxis4t+AcwwxlTEtUClupH23FVfMhSoMMYEAKwwvwwYBiwTkWUAInK+iHwp\nIqtF5FVrLpzm+boftObaXi4i4+LVEKU6ouGu+pIPgJEisk1EnhSRM40xjwElwFnGmLOs3vzdwLnG\nmJOAlcTmJW9Wa4yZTOzJwUeOdQOU6iydFVL1GcYYn4hMB74JnAW8Ige/zetUYi9S+NyardIDfNlq\n/aJWvz7csxUr1XUa7qpPMbHpdz8GPhaR9fxzUqdmQmzO9QWHOsQhPivVq+iwjOozRGS8iOS2WjQV\n2A3UE3vtH8BXwGnN4+nWbH/Ht9rne61+bd2jV6pX0Z676kvSgN9bU/CGib3a7AZgAfCeiJRY4+7/\nB1gkIknWfncTm4kUoL+IrAMC1n5K9Up6K6RSnWS9fEJvmVQJQYdllFLKhrTnrpRSNqQ9d6WUsiEN\nd6WUsiENd6WUsiENd6WUsiENd6WUsqH/D6B4aasovPiZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27dee5324e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(losses[50:], mean_losses, train_aucs[1:], valid_aucs, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
